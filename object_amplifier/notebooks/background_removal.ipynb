{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from skimage import io, transform\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms#, utils\n",
    "# import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "from data_loader import RescaleT\n",
    "from data_loader import ToTensorLab\n",
    "from data_loader import SalObjDataset\n",
    "\n",
    "os.chdir(os.getcwd() + \"/../../\")\n",
    "from object_amplifier.model import U2NET, U2NETP\n",
    "\n",
    "from object_amplifier import DATA_PATH, MODELS_PATH, IMAGE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the predicted SOD probability map\n",
    "def normPRED(d):\n",
    "    ma = torch.max(d)\n",
    "    mi = torch.min(d)\n",
    "\n",
    "    dn = (d-mi)/(ma-mi)\n",
    "\n",
    "    return dn\n",
    "\n",
    "def save_output(image_name,pred,d_dir):\n",
    "\n",
    "    predict = pred\n",
    "    predict = predict.squeeze()\n",
    "    predict_np = predict.cpu().data.numpy()\n",
    "\n",
    "    im = Image.fromarray(predict_np*255).convert('RGB')\n",
    "    img_name = image_name.split(os.sep)[-1]\n",
    "    image = io.imread(image_name)\n",
    "    imo = im.resize((image.shape[1],image.shape[0]),resample=Image.BILINEAR)\n",
    "\n",
    "    aaa = img_name.split(\".\")\n",
    "    bbb = aaa[0:-1]\n",
    "    imidx = bbb[0]\n",
    "    for i in range(1,len(bbb)):\n",
    "        imidx = imidx + \".\" + bbb[i]\n",
    "\n",
    "    imo.save(d_dir+imidx+'.png')\n",
    "\n",
    "def remove_background():\n",
    "\n",
    "    # --------- 1. get image path and name ---------\n",
    "    model_name='u2net'#u2netp\n",
    "\n",
    "\n",
    "\n",
    "    image_dir=os.path.join(IMAGE_PATH, 'input')\n",
    "    prediction_dir=os.path.join(IMAGE_PATH,model_name+'_results'+os.sep)\n",
    "    model_dir = os.path.join(MODELS_PATH,model_name+'.pth')\n",
    "\n",
    "    img_name_list = glob.glob(image_dir + os.sep + '*')\n",
    "    print(img_name_list)\n",
    "\n",
    "    # --------- 2. dataloader ---------\n",
    "    #1. dataloader\n",
    "    test_salobj_dataset = SalObjDataset(img_name_list = img_name_list,\n",
    "                                        lbl_name_list = [],\n",
    "                                        transform=transforms.Compose([RescaleT(320),\n",
    "                                                                      ToTensorLab(flag=0)])\n",
    "                                        )\n",
    "                                        \n",
    "    test_salobj_dataloader = DataLoader(test_salobj_dataset,\n",
    "                                        batch_size=1,\n",
    "                                        shuffle=False,\n",
    "                                        num_workers=1)\n",
    "    \n",
    "    # --------- 3. model define ---------\n",
    "    if(model_name=='u2net'):\n",
    "        print(\"...load U2NET---173.6 MB\")\n",
    "        net = U2NET(3,1)\n",
    "    elif(model_name=='u2netp'):\n",
    "        print(\"...load U2NEP---4.7 MB\")\n",
    "        net = U2NETP(3,1)\n",
    "    \n",
    "    print(\"Loading trained model\")\n",
    "    net.load_state_dict(torch.load(model_dir, map_location=torch.device('cpu')))\n",
    "    if torch.cuda.is_available():\n",
    "        net.cuda()\n",
    "    net.eval()\n",
    "\n",
    "    # --------- 4. inference for each image ---------\n",
    "    print(\"Inferencing for each image\")\n",
    "    for i_test, data_test in enumerate(test_salobj_dataloader):\n",
    "\n",
    "        print(\"inferencing:\",img_name_list[i_test].split(os.sep)[-1])\n",
    "\n",
    "        inputs_test = data_test['image']\n",
    "        inputs_test = inputs_test.type(torch.FloatTensor)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            inputs_test = Variable(inputs_test.cuda())\n",
    "        else:\n",
    "            inputs_test = Variable(inputs_test)\n",
    "\n",
    "        d1,d2,d3,d4,d5,d6,d7= net(inputs_test)\n",
    "\n",
    "        # normalization\n",
    "        pred = d1[:,0,:,:]\n",
    "        pred = normPRED(pred)\n",
    "\n",
    "        # save results to test_results folder\n",
    "        if not os.path.exists(prediction_dir):\n",
    "            os.makedirs(prediction_dir, exist_ok=True)\n",
    "        save_output(img_name_list[i_test],pred,prediction_dir)\n",
    "\n",
    "        del d1,d2,d3,d4,d5,d6,d7\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/ericmatamoros/Desktop/object_amplifier/object_amplifier/data/images/input/input_1.jpg', '/Users/ericmatamoros/Desktop/object_amplifier/object_amplifier/data/images/input/input_2.jpg', '/Users/ericmatamoros/Desktop/object_amplifier/object_amplifier/data/images/input/input_3.jpeg']\n",
      "...load U2NET---173.6 MB\n",
      "Loading trained model\n",
      "Inferencing for each image\n",
      "inferencing: input_1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ericmatamoros/miniconda3/lib/python3.10/site-packages/torch/nn/functional.py:3769: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferencing: input_2.jpg\n",
      "inferencing: input_3.jpeg\n"
     ]
    }
   ],
   "source": [
    "remove_background()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subimage\n",
    "subimage=Image.open('/Users/ericmatamoros/Desktop/object_amplifier/object_amplifier/data/images/u2net_results/input_1.png')\n",
    "#originalimage\n",
    "original=Image.open('/Users/ericmatamoros/Desktop/object_amplifier/object_amplifier/data/images/input/input_1.jpg')\n",
    "\n",
    "subimage=subimage.convert(\"RGBA\")\n",
    "original=original.convert(\"RGBA\")\n",
    "\n",
    "subdata=subimage.getdata()\n",
    "ogdata=original.getdata()\n",
    "\n",
    "newdata=[]\n",
    "for i in range(subdata.size[0]*subdata.size[1]):\n",
    "  if subdata[i][0]==0 and subdata[i][1]==0 and subdata[i][2]==0:\n",
    "    newdata.append((255,255,255,0))\n",
    "  else:\n",
    "    newdata.append(ogdata[i])\n",
    "subimage.putdata(newdata)\n",
    "subimage.save('/Users/ericmatamoros/Desktop/object_amplifier/object_amplifier/data/images/output/input_1.png',\"PNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
